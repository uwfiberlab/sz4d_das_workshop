{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6555d398",
   "metadata": {},
   "source": [
    "# Template Matching Tutorial Notebook \n",
    "\n",
    "\n",
    "\n",
    "Sections:\n",
    "1. Libraries\n",
    "2. Template construction \n",
    "3. Template visualization\n",
    "3. Matching / cross-correlation window \n",
    "4. Plotting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8120a2de",
   "metadata": {},
   "source": [
    "![Data](./seismicitymap.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59bdcd2",
   "metadata": {},
   "source": [
    "Repo: https://dasway.ess.washington.edu/mora/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6071ad65",
   "metadata": {},
   "source": [
    "## 0. Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af27dc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, glob\n",
    "from datetime import datetime, timezone, timedelta\n",
    "from typing import List\n",
    "from scipy.signal import butter\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import time\n",
    "from templatematching_cc import *\n",
    "from getanalisisfiles import *\n",
    "from template_maker_w import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f35dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- settings you likely only tweak here --------\n",
    "base_year_dir = \"/data/fast0/rainier50Hz/2023/\"\n",
    "# propagate this value into the MODULE\n",
    "\n",
    "set_base_year_dir(base_year_dir)\n",
    "\n",
    "# where to write templates and CC results\n",
    "templates_dir = \"/data/data2/workshop/temp_files\"\n",
    "cc_base       = \"/data/data2/workshop/cc_results\"\n",
    "os.makedirs(templates_dir, exist_ok=True)\n",
    "os.makedirs(cc_base, exist_ok=True)\n",
    "\n",
    "# AUGUST window for templates (USGS events):\n",
    "tmpl_start_dt = datetime(2023, 8, 27, 10, 0)\n",
    "tmpl_end_dt   = datetime(2023, 8, 27, 10, 30)\n",
    "\n",
    "# MATCHING window (example: full Oct 27 UTC)\n",
    "\n",
    "match_start = \"2023-08-27_09.00\"\n",
    "match_end   = \"2023-08-27_11.00\"\n",
    "\n",
    "# DAS + filter\n",
    "chan_min, chan_max = 1000,1200\n",
    "template_size = 5.0\n",
    "fs = 50\n",
    "samples_per_file = int(60 * fs)\n",
    "b, a = butter(2, (2.0, 10.0), 'bp', fs=fs)\n",
    "\n",
    "# filename pattern \n",
    "rx = re.compile(r\"rainier_50Hz_(\\d{4}-\\d{2}-\\d{2})_(\\d{2})\\.(\\d{2})\\.(\\d{2})_UTC\\.h5$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1607e6ff",
   "metadata": {},
   "source": [
    "## 1. Template construction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d02e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean this away\n",
    "#def yday(dt: datetime) -> int:\n",
    "#    return dt.timetuple().tm_yday\n",
    "\n",
    "#def path_for_time(t_utc: datetime) -> str:\n",
    "#    \"\"\"Return full path to file that covers t_utc, based on minute-aligned filenames.\"\"\"\n",
    "#    t_utc = t_utc.replace(tzinfo=timezone.utc)\n",
    "#    # files are 1-minute long and named ..._HH.MM.00_UTC.h5\n",
    "#    t0 = t_utc.replace(second=0, microsecond=0)\n",
    "#    day_dir = os.path.join(base_year_dir, f\"{yday(t0):03d}\")\n",
    "#    fn = f\"rainier_50Hz_{t0.strftime('%Y-%m-%d_%H.%M')}.00_UTC.h5\"\n",
    "#    return os.path.join(day_dir, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbf8f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- A) TEMPLATES (AUGUST) ----------------\n",
    "events = search(starttime=tmpl_start_dt,\n",
    "                endtime=tmpl_end_dt,\n",
    "                latitude=46.879967, longitude=-121.726906,\n",
    "                maxradius=35/111.32)\n",
    "event_df = get_summary_data_frame(events).sort_values(\"time\")\n",
    "print(f\"[templates] usgs events in august: {len(event_df)}\")\n",
    "\n",
    "found_files = []\n",
    "original_dates_fixed = []\n",
    "\n",
    "miss = 0\n",
    "hit  = 0\n",
    "for _, row in event_df.iterrows():\n",
    "    # event time as naive UTC datetime\n",
    "    t_evt = row[\"time\"]  # should already be UTC (pandas/obspy)\n",
    "    if isinstance(t_evt, str):\n",
    "        t_evt = datetime.strptime(\n",
    "            t_evt.replace(\"_\",\" \").replace(\".\",\":\"),\n",
    "            \"%Y-%m-%d %H:%M:%S\"\n",
    "        ).replace(tzinfo=timezone.utc)\n",
    "    else:\n",
    "        t_evt = pd.Timestamp(t_evt).to_pydatetime().replace(tzinfo=timezone.utc)\n",
    "\n",
    "    p = path_for_time(t_evt)\n",
    "    if os.path.isfile(p):\n",
    "        found_files.append(p)\n",
    "        # template_maker2 expects 'YYYY-MM-DD HH:MM:SS.%f' for the event time\n",
    "        original_dates_fixed.append(t_evt.strftime(\"%Y-%m-%d %H:%M:%S.%f\"))\n",
    "        hit += 1\n",
    "    else:\n",
    "       # print(f\"No raw file for event: {t_evt.strftime('%Y-%m-%d_%H.%M.%S')}\")\n",
    "        miss += 1\n",
    "\n",
    "if hit > 0:\n",
    "    process_files_to_cut(\n",
    "        found_files, original_dates_fixed,\n",
    "        base_year_dir, templates_dir,\n",
    "        chan_min, chan_max, template_size\n",
    "    )\n",
    "else:\n",
    "    print(\"[templates] no templates cut (no august raw found)\")\n",
    "\n",
    "template_list = glob.glob(os.path.join(templates_dir, \"*\"))\n",
    "#print(f\"[templates] templates found on disk: {len(template_list)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f30d51",
   "metadata": {},
   "source": [
    "## 2. Plotting 1 template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0c4253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path of one example, need to make it prettier\\\n",
    "p = \"/data/data2/workshop/temp_files/2023-08-27_10-10-23.740000.h5\"  \n",
    "with h5py.File(p, \"r\") as h5:\n",
    "    cand = [\"data\",\"phase\",\"strain_rate\",\"strainrate\",\"/data\",\"/phase\",\"/strain_rate\",\"/strainrate\"]\n",
    "    ds = next((h5[k] for k in cand if k in h5), None)\n",
    "    if ds is None:\n",
    "        names=[]; h5.visititems(lambda n,o: names.append(n) if isinstance(o,h5py.Dataset) and not names else None)\n",
    "        ds = h5[names[0]]\n",
    "    A  = ds[()]\n",
    "    fs = float(ds.attrs.get(\"sampling_rate\", ds.attrs.get(\"Fs\", 50.0)))\n",
    "M = A if A.ndim==2 and A.shape[0]>=A.shape[1] else (A.T if A.ndim==2 else A[:,None])\n",
    "t = np.arange(M.shape[0])/fs\n",
    "plt.imshow(M.T, aspect=\"auto\", vmin =- 0.1, vmax = 0.1, extent=[t.min(), t.max(), 0, M.shape[1]], cmap=\"seismic\")\n",
    "plt.xlabel(\"Time (s)\"); plt.ylabel(\"Channel\"); plt.colorbar(label=\"phase\"); plt.tight_layout()\n",
    "plt.title('Raw data')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43f3985",
   "metadata": {},
   "source": [
    "## 2. Matching / cross-correlation window (serial, no multiprocessing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722ac9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = build_file_list_julian(match_start, match_end)\n",
    "#print(f\"[matching] raw files: {len(file_list)} | templates: {len(template_list)}\")\n",
    "\n",
    "cc_out = os.path.join(cc_base, f\"CC_{int(template_size)}sec-tem_{match_start}-{match_end}\")\n",
    "os.makedirs(cc_out, exist_ok=True)\n",
    "\n",
    "if not file_list:\n",
    "    print(\"[matching] no raw files in the chosen window\")\n",
    "elif not template_list:\n",
    "    print(\"[matching] no templates available\")\n",
    "else:\n",
    "    t0 = time.perf_counter()\n",
    "    process_files_dos(\n",
    "        file_list, template_list,\n",
    "        chan_min, chan_max, (chan_max - chan_min),\n",
    "        samples_per_file, b, a, cc_out\n",
    "    )\n",
    "    dt = time.perf_counter() - t0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34d349d",
   "metadata": {},
   "source": [
    "## 3. Timestamps and plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3444e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = build_file_list_julian(match_start, match_end)\n",
    "print(len(file_list))\n",
    "ts_h5_dir= '/data/data2/workshop/cc_results/timestamps'\n",
    "h5_path = create_timestamps_h5(file_list, ts_h5_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5c9362",
   "metadata": {},
   "outputs": [],
   "source": [
    "Template_folder_1 = '/data/data2/workshop/cc_results/CC_5sec-tem_2023-08-27_09.00-2023-08-27_11.00/2023-08-27_10-10-23.740000'\n",
    "\n",
    "time_tag = f\"{match_start}-{match_end}\"  # e.g. \"2023-08-27_09.00-2023-08-27_12.30\"\n",
    "\n",
    "CC_DIR  = os.path.join(\n",
    "    cc_base,\n",
    "    f\"CC_{int(template_size)}sec-tem_{time_tag}\",\n",
    "    Template_folder_1,\n",
    ")\n",
    "H5_FILE = h5_path  # from create_timestamps_h5\n",
    "\n",
    "print(\"[CC_DIR ]\", CC_DIR)\n",
    "print(\"[H5_FILE]\", H5_FILE)\n",
    "\n",
    "t_abs, t_abs_aligned, cc, cc_files = load_cc_and_time(\n",
    "    CC_DIR,\n",
    "    H5_FILE,\n",
    "    template_size_sec=template_size,\n",
    ")\n",
    "\n",
    "print(f\"[align] N = {len(cc)}, range: {t_abs_aligned[0]} → {t_abs_aligned[-1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684a128a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting\n",
    "# --- load timestamps and align with CC ---\n",
    "with h5py.File(h5_path, \"r\") as h5:\n",
    "    ts_raw = h5[\"timestamps\"][:]          # microseconds since epoch\n",
    "\n",
    "# make sure lengths match\n",
    "N = min(len(cc), len(ts_raw))\n",
    "cc_plot = np.asarray(cc[:N], float)\n",
    "ts_raw = ts_raw[:N]\n",
    "\n",
    "# convert to Python datetime for plotting\n",
    "epoch = datetime(1970, 1, 1)\n",
    "time_utc = np.array(\n",
    "    [epoch + timedelta(microseconds=int(t)) for t in ts_raw]\n",
    ")\n",
    "\n",
    "print(\"N =\", N)\n",
    "print(\"time range:\", time_utc[0], \"→\", time_utc[-1])\n",
    "\n",
    "# --- simple plot: CC vs time ---\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(time_utc, abs(cc_plot), lw=0.4)\n",
    "plt.xlabel(\"Time (UTC)\")\n",
    "plt.ylabel(\"Correlation (CC)\")\n",
    "plt.title(\"Results for cc for 1 template\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d21127",
   "metadata": {},
   "outputs": [],
   "source": [
    "Template_folder_2 = '/data/data2/workshop/cc_results/CC_5sec-tem_2023-08-27_09.00-2023-08-27_11.00/2023-08-27_10-26-15.030000'\n",
    "\n",
    "time_tag = f\"{match_start}-{match_end}\"  # e.g. \"2023-08-27_09.00-2023-08-27_12.30\"\n",
    "\n",
    "CC_DIR  = os.path.join(\n",
    "    cc_base,\n",
    "    f\"CC_{int(template_size)}sec-tem_{time_tag}\",\n",
    "    Template_folder_2,\n",
    ")\n",
    "H5_FILE = h5_path  # from create_timestamps_h5\n",
    "\n",
    "print(\"[CC_DIR ]\", CC_DIR)\n",
    "print(\"[H5_FILE]\", H5_FILE)\n",
    "\n",
    "t_abs, t_abs_aligned, cc, cc_files = load_cc_and_time(\n",
    "    CC_DIR,\n",
    "    H5_FILE,\n",
    "    template_size_sec=template_size,\n",
    ")\n",
    "\n",
    "print(f\"[align] N = {len(cc)}, range: {t_abs_aligned[0]} → {t_abs_aligned[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fb9846",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(h5_path, \"r\") as h5:\n",
    "    ts_raw = h5[\"timestamps\"][:]          # microseconds since epoch\n",
    "\n",
    "# make sure lengths match\n",
    "N = min(len(cc), len(ts_raw))\n",
    "cc_plot = np.asarray(cc[:N], float)\n",
    "ts_raw = ts_raw[:N]\n",
    "\n",
    "# convert to Python datetime for plotting\n",
    "epoch = datetime(1970, 1, 1)\n",
    "time_utc = np.array(\n",
    "    [epoch + timedelta(microseconds=int(t)) for t in ts_raw]\n",
    ")\n",
    "\n",
    "print(\"N =\", N)\n",
    "print(\"time range:\", time_utc[0], \"→\", time_utc[-1])\n",
    "\n",
    "# --- simple plot: CC vs time ---\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(time_utc, abs(cc_plot), lw=0.4)\n",
    "plt.xlabel(\"Time (UTC)\")\n",
    "plt.ylabel(\"Correlation (CC)\")\n",
    "plt.title(\"Results for cc for 2 template\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec70a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "THRESH = 0.117          # threshold on |CC|\n",
    "TOL_SEC = 6.0         # time tolerance to merge hits into one event\n",
    "\n",
    "# --- load timestamps and align with CC ---\n",
    "with h5py.File(h5_path, \"r\") as h5:\n",
    "    ts_raw = h5[\"timestamps\"][:]          # microseconds since epoch\n",
    "\n",
    "# make sure lengths match\n",
    "N = min(len(cc), len(ts_raw))\n",
    "cc_plot = np.asarray(cc[:N], float)\n",
    "ts_raw = ts_raw[:N]\n",
    "\n",
    "# convert to Python datetime for plotting\n",
    "epoch = datetime(1970, 1, 1)\n",
    "time_utc = np.array(\n",
    "    [epoch + timedelta(microseconds=int(t)) for t in ts_raw]\n",
    ")\n",
    "\n",
    "print(\"N =\", N)\n",
    "print(\"time range:\", time_utc[0], \"→\", time_utc[-1])\n",
    "\n",
    "# --- find samples over threshold (absolute value) ---\n",
    "cc_abs = np.abs(cc_plot)\n",
    "idx_hits = np.where(cc_abs >= THRESH)[0]\n",
    "\n",
    "print(f\"\\nNumber of samples with |CC| >= {THRESH}: {len(idx_hits)}\")\n",
    "\n",
    "if len(idx_hits) > 0:\n",
    "    hit_times = time_utc[idx_hits]\n",
    "    hit_vals  = cc_abs[idx_hits]\n",
    "\n",
    "    # --- cluster hits within TOL_SEC and keep max in each cluster ---\n",
    "    clusters = []\n",
    "    start = 0\n",
    "    for i in range(1, len(hit_times)):\n",
    "        dt = (hit_times[i] - hit_times[i-1]).total_seconds()\n",
    "        if dt > TOL_SEC:\n",
    "            clusters.append((start, i))   # [start, i)\n",
    "            start = i\n",
    "    clusters.append((start, len(hit_times)))  # last cluster\n",
    "\n",
    "    event_times = []\n",
    "    event_vals = []\n",
    "    for s, e in clusters:\n",
    "        # indices within this cluster\n",
    "        local_max_idx = s + np.argmax(hit_vals[s:e])\n",
    "        event_times.append(hit_times[local_max_idx])\n",
    "        event_vals.append(hit_vals[local_max_idx])\n",
    "\n",
    "    event_times = np.array(event_times)\n",
    "    event_vals  = np.array(event_vals)\n",
    "\n",
    "    print(f\"\\nNumber of unique events (tolerance {TOL_SEC} s): {len(event_times)}\")\n",
    "    for t, v in zip(event_times, event_vals):\n",
    "        print(f\"  {t}  |CC| = {v:.3f}\")\n",
    "else:\n",
    "    event_times = np.array([])\n",
    "    event_vals  = np.array([])\n",
    "\n",
    "# --- plot CC vs time with threshold + unique-event markers ---\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(time_utc, cc_abs, lw=0.4, label=\"|CC|\")\n",
    "plt.axhline(THRESH, color=\"r\", linestyle=\"--\", label=f\"threshold = {THRESH}\")\n",
    "\n",
    "if event_times.size > 0:\n",
    "    plt.scatter(event_times, event_vals, s=25, color=\"r\", label=\"unique events\")\n",
    "\n",
    "plt.xlabel(\"Time (UTC)\")\n",
    "plt.ylabel(\"|Correlation (CC)|\")\n",
    "plt.title(\"CC vs Time (unique peaks with 6 s tolerance)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788ad97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- IRIS / ComCat query for the same time window ----\n",
    "client = Client(\"IRIS\")\n",
    "\n",
    "start = UTCDateTime(time_utc[0])\n",
    "end   = UTCDateTime(time_utc[-1])\n",
    "\n",
    "LAT, LON = 46.879967, -121.726906\n",
    "MAXR_KM = 35.0\n",
    "MAXR_DEG = MAXR_KM / 111.32\n",
    "\n",
    "cat = client.get_events(\n",
    "    starttime=start,\n",
    "    endtime=end,\n",
    "    latitude=LAT,\n",
    "    longitude=LON,\n",
    "    maxradius=MAXR_DEG,\n",
    ")\n",
    "\n",
    "cat_times = np.array([ev.origins[0].time.datetime for ev in cat])\n",
    "cat_mags  = np.array([ev.magnitudes[0].mag if ev.magnitudes else np.nan for ev in cat])\n",
    "\n",
    "print(f\"[IRIS] catalog events in window: {len(cat_times)}\")\n",
    "for t, m in zip(cat_times, cat_mags):\n",
    "    if np.isnan(m):\n",
    "        print(f\"  {t}  M=?\")\n",
    "    else:\n",
    "        print(f\"  {t}  M={m:.2f}\")\n",
    "\n",
    "# ---- compare DAS events to catalog (time tolerance) ----\n",
    "TOL_SEC = 10  # tolerance for matching catalog events, e.g. ±20 s\n",
    "tol = np.timedelta64(int(TOL_SEC * 1000), \"ms\")\n",
    "\n",
    "das64 = event_times.astype(\"datetime64[ms]\")\n",
    "cat64 = cat_times.astype(\"datetime64[ms]\") if len(cat_times) else np.array([])\n",
    "\n",
    "matched_idx = []\n",
    "new_idx = []\n",
    "\n",
    "for i, t in enumerate(das64):\n",
    "    if cat64.size and np.any(np.abs(cat64 - t) <= tol):\n",
    "        matched_idx.append(i)\n",
    "    else:\n",
    "        new_idx.append(i)\n",
    "\n",
    "print(f\"\\nDAS unique events: {len(event_times)}\")\n",
    "print(f\"  matched to catalog (±{TOL_SEC}s): {len(matched_idx)}\")\n",
    "print(f\"  no catalog match: {len(new_idx)}\")\n",
    "\n",
    "for i in matched_idx:\n",
    "    print(f\"  MATCHED: {event_times[i]}  |CC|={event_vals[i]:.3f}\")\n",
    "\n",
    "for i in new_idx:\n",
    "    print(f\"  NEW:     {event_times[i]}  |CC|={event_vals[i]:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
